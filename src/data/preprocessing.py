import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer
from sklearn.feature_selection import VarianceThreshold

def load_raw_data(file_path):
    """
    è®€å–åŸå§‹è³‡æ–™
    """
    print(f"ğŸ“‚ è®€å–åŸå§‹è³‡æ–™: {file_path}")
    return pd.read_csv(file_path)

def load_and_preprocess_baseline(file_path, variance_threshold=0.01, include_ids=True):
    """
    åŸºç·šæ¨¡å‹ (Baseline) çš„è³‡æ–™å‰è™•ç†
    ä½¿ç”¨ One-Hot Encoding ä¸¦åŠ å…¥ VarianceThreshold ç‰¹å¾µé¸æ“‡
    :param include_ids: æ˜¯å¦ä¿ç•™ DRUG_ID å’Œ COSMIC_ID (True=é«˜åˆ†æ¨¡å¼, False=æ³›åŒ–æ¨¡å¼)
    """
    print(f"Step 1: æ­£åœ¨è®€å–è³‡æ–™ä¸¦é€²è¡Œå‰è™•ç† (Baseline): {file_path}...")
    print(f"   -> æ¨¡å¼: {'ä¿ç•™ ID ç‰¹å¾µ (é«˜åˆ†æ¨¡å¼)' if include_ids else 'ç§»é™¤ ID ç‰¹å¾µ (æ³›åŒ–æ¨¡å¼)'}")

    df = pd.read_csv(file_path)
    target = 'LN_IC50'
    
    # èˆ‡ DL ä¿æŒä¸€è‡´ï¼šç§»é™¤ç›®æ¨™è®Šæ•¸ç¼ºå¤±å€¼
    df = df.dropna(subset=[target])

    # åŸºç¤ç§»é™¤æ¬„ä½ (Data Leakage)
    drop_cols = [
        'CELL_LINE_NAME', 'DRUG_NAME', 
        'AUC', 'Z_SCORE', 'RMSE',
        'NLME_RESULT_ID', 'NLME_CURVE_ID', 'SANGER_MODEL_ID'
    ]
    
    # å¦‚æœä¸åŒ…å« IDï¼Œå‰‡é¡å¤–ç§»é™¤ ID æ¬„ä½
    if not include_ids:
        drop_cols.extend(['DRUG_ID', 'COSMIC_ID'])
        print("   -> å·²è¨­å®šç§»é™¤ DRUG_ID èˆ‡ COSMIC_ID")
        
    # ç§»é™¤ç„¡æ„ç¾©çš„ Y/N è³‡æ–™å­˜åœ¨æ¨™è¨˜ (Data Availability Flags) - èˆ‡ DL ä¸€è‡´
    drop_cols.extend([
        'Gene Expression', 'CNA', 'Methylation', 'Drug Response', 
        'Exome mutation', 'Whole Genome Sequencing (WGS)'
    ])

    # åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
    # Method 2: Blind Cell Split (Prevent Data Leakage) - èˆ‡ DL ä¿æŒä¸€è‡´
    if 'COSMIC_ID' in df.columns:
        print("   -> æ¨¡å¼: Blind Cell Split (ä¾æ“š COSMIC_ID åˆ‡åˆ†)")
        from sklearn.model_selection import GroupShuffleSplit
        
        # å³ä½¿æˆ‘å€‘ä¸Šé¢ drop äº† COSMIC_IDï¼Œæˆ‘å€‘å¯ä»¥ç”¨åŸå§‹ df ä¾†å–å¾— Group
        # æ³¨æ„ï¼šæˆ‘å€‘ä¹‹å‰ drop äº† COSMIC_ID (line 39), ä½†å¦‚æœ include_ids=False, æˆ‘å€‘éœ€è¦å®ƒä¾† split
        # ä¿®æ­£ï¼šline 39 å·²ç¶“ drop äº†ã€‚æˆ‘å€‘å¯ä»¥ç”¨åŸå§‹ df çš„ index ä¾†å°æ‡‰ï¼Œæˆ–è€…åœ¨ drop ä¹‹å‰å…ˆå–å‡ºä¾†åš group
        # æ›´å¥½ä½œæ³•ï¼šä¸è¦åœ¨ line 39 drop COSMIC_IDï¼Œè€Œæ˜¯ç­‰åˆ° split å®Œå¾Œå†å¾ X ä¸­ç§»é™¤
        
        pass # Will implement logic below
    
    # Re-logic: We need to handle COSMIC_ID carefully.
    # Let's refactor: Keep COSMIC_ID until split, then drop.
    pass

    # New implementation logic
    # 1. Drop non-essential cols but KEEP COSMIC_ID for splitting
    cols_to_drop_early = [c for c in drop_cols if c not in ['COSMIC_ID', 'DRUG_ID']]
    # If include_ids=False, we explicitly want to drop them from FEATURES, but we need COSMIC_ID for SPLITTING.
    
    df_cleaned = df.drop(columns=[c for c in cols_to_drop_early if c in df.columns])
    
    # One-Hot Encoding
    categorical_cols = df_cleaned.select_dtypes(include=['object']).columns
    df_processed = pd.get_dummies(df_cleaned, columns=categorical_cols, drop_first=True)
    
    X = df_processed.drop(columns=[target])
    y = df_processed[target]
    
    # Split
    if 'COSMIC_ID' in df.columns:
         print("   -> æ¨¡å¼: Blind Cell Split (ä¾æ“š COSMIC_ID åˆ‡åˆ†)")
         from sklearn.model_selection import GroupShuffleSplit
         gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
         groups = df['COSMIC_ID']
         
         train_idx, test_idx = next(gss.split(X, y, groups=groups))
         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
         y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
    else:
         # Fallback
         stratify_col = None
         if 'GDSC Tissue descriptor 1' in df_cleaned.columns:
             stratify_col = df_cleaned['GDSC Tissue descriptor 1'].fillna('Unknown')
         X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=stratify_col
         )
         
    # Now remove IDs from X if include_ids=False
    if not include_ids:
        # COSMIC_ID and DRUG_ID might be in X
        cols_to_remove = [c for c in ['COSMIC_ID', 'DRUG_ID'] if c in X_train.columns]
        if cols_to_remove:
            X_train = X_train.drop(columns=cols_to_remove)
            X_test = X_test.drop(columns=cols_to_remove)
            print(f"   -> Split å¾Œå·²ç§»é™¤ ID æ¬„ä½: {cols_to_remove}")
    
    # --- å„ªåŒ–ï¼šç‰¹å¾µé¸æ“‡ (ç§»é™¤ä½è®Šç•°æ•¸ç‰¹å¾µ) ---
    print(f"   -> åŸ·è¡Œç‰¹å¾µé¸æ“‡ (VarianceThreshold={variance_threshold})...")
    selector = VarianceThreshold(threshold=variance_threshold)
    
    # åƒ…åœ¨è¨“ç·´é›†ä¸Š fit
    X_train_selected = selector.fit_transform(X_train)
    X_test_selected = selector.transform(X_test)
    
    # ç²å–ä¿ç•™çš„ç‰¹å¾µåç¨± (Use X_train.columns as it matches the fitted data)
    feature_names = X_train.columns[selector.get_support()]
    print(f"      ä¿ç•™ç‰¹å¾µæ•¸: {len(feature_names)} / {X_train.shape[1]}")
    
    # è½‰æ›å› DataFrame ä»¥ä¿æŒæ¬„ä½åç¨± (å° XGBoost é‡è¦)
    X_train = pd.DataFrame(X_train_selected, columns=feature_names, index=X_train.index)
    X_test = pd.DataFrame(X_test_selected, columns=feature_names, index=X_test.index)

    # ç¢ºä¿ DRUG_ID å’Œ COSMIC_ID è¢«è¦–ç‚ºæ•¸å€¼ç‰¹å¾µ (å¦‚æœå®ƒå€‘åœ¨ç‰¹å¾µé¸æ“‡ä¸­è¢«ä¿ç•™)
    # é€™è£¡ä¸éœ€è¦é¡å¤–æ“ä½œï¼Œå› ç‚ºå®ƒå€‘åŸæœ¬å°±æ˜¯æ•¸å€¼

    print(f"   -> è³‡æ–™å½¢ç‹€: X_train={X_train.shape}, X_test={X_test.shape}")

    return X_train, X_test, y_train, y_test, feature_names

def load_and_preprocess_dl(file_path, include_ids=True):
    """
    æ·±åº¦å­¸ç¿’æ¨¡å‹ (Deep Learning) çš„è³‡æ–™å‰è™•ç†
    ä½¿ç”¨ Label Encodingï¼Œä¸¦å°‡ç‰¹å¾µæ‹†åˆ†ç‚º Cell Line å’Œ Drug å…©çµ„
    :param include_ids: æ˜¯å¦ä¿ç•™ DRUG_ID å’Œ COSMIC_ID
    """
    print(f"   -> æ¨¡å¼: {'ä¿ç•™ ID ç‰¹å¾µ' if include_ids else 'ç§»é™¤ ID ç‰¹å¾µ'}")
    
    df = pd.read_csv(file_path)
    
    print(f"   åŸå§‹è³‡æ–™å½¢ç‹€: {df.shape}")
    
    # ç§»é™¤ç›®æ¨™è®Šæ•¸ç¼ºå¤±å€¼
    df_clean = df.dropna(subset=['LN_IC50'])
    
    # å®šç¾©ç‰¹å¾µç¾¤çµ„
    # 1. è—¥ç‰©ç‰¹å¾µ (ID vs Numeric)
    # DRUG_ID ç‰¹æ®Šè™•ç†ï¼šå¦‚æœæœ‰ IDï¼Œå°‡å…¶ç¨ç«‹å‡ºä¾†åš Embeddingï¼Œä¸æ”¾åœ¨ numeric ä¸­
    drug_numeric_cols = [] 
    # å¦‚æœæœ‰å…¶ä»–è—¥ç‰©æ•¸å€¼ç‰¹å¾µ (ä¾‹å¦‚åˆ†å­é‡)ï¼Œä½†åœ¨é€™ä»½è³‡æ–™é›†ä¼¼ä¹æ²’æœ‰ï¼Œé™¤éæœ‰é¡å¤– merge
    # å‡è¨­ç›®å‰æ²’æœ‰å…¶ä»–è—¥ç‰©ç‰¹å¾µï¼Œdrug_numeric_cols ç‚ºç©º (è‹¥ No_IDs) æˆ–ä¿ç•™é ID æ¬„ä½
    
    # å®šç¾© Embedding/Multi-hot ç‰¹å¾µ
    target_col = 'TARGET'
    pathway_col = 'TARGET_PATHWAY'
    
    # åŸºç¤ç§»é™¤æ¬„ä½
    exclude_cols = [
        'CELL_LINE_NAME', 'DRUG_NAME', 
        'AUC', 'Z_SCORE', 'RMSE', 
        'NLME_RESULT_ID', 'NLME_CURVE_ID', 'SANGER_MODEL_ID',
        'LN_IC50', target_col, pathway_col,
        # ç§»é™¤ç„¡æ„ç¾©çš„ Y/N è³‡æ–™å­˜åœ¨æ¨™è¨˜ (Data Availability Flags)
        'Gene Expression', 'CNA', 'Methylation', 'Drug Response', 
        'Exome mutation', 'Whole Genome Sequencing (WGS)'
    ]
    # DRUG_ID ä¸åœ¨ exclude_cols ä¸­ (é™¤é No_IDs)ï¼Œä½†ä¹Ÿä¸ç®— cell feature
    if not include_ids:
        exclude_cols.append('DRUG_ID')
        exclude_cols.append('COSMIC_ID')
    
    # ---------------------------------------------------------
    # 1. è™•ç†ç´°èƒç‰¹å¾µ (Cell Features) - One-Hot Encoding
    # ---------------------------------------------------------
    print("\nğŸ”„ è™•ç†ç´°èƒç‰¹å¾µ (One-Hot Encoding)...")
    
    # æ½›åœ¨çš„ç´°èƒç‰¹å¾µæ¬„ä½ = æ‰€æœ‰æ¬„ä½ - æ’é™¤æ¬„ä½ - (Target/Pathway å·²æ’é™¤) - (DRUG_ID è‹¥å­˜åœ¨)
    potential_cell_cols = [c for c in df_clean.columns if c not in exclude_cols]
    
    # ç¢ºä¿ DRUG_ID å’Œ COSMIC_ID ä¸è¢«ç®—ä½œç´°èƒç‰¹å¾µ (å³ä½¿ include_ids=True)
    if 'DRUG_ID' in potential_cell_cols: potential_cell_cols.remove('DRUG_ID')
    if 'COSMIC_ID' in potential_cell_cols: potential_cell_cols.remove('COSMIC_ID') # COSMIC_ID åƒ…ç”¨æ–¼ Splitï¼Œä¸ä½œç‚ºç‰¹å¾µè¼¸å…¥? 
    # User é€šå¸¸ä¸å¸Œæœ› COSMIC_ID é€²å…¥æ¨¡å‹ (Blind Cell)ï¼Œé™¤é embeddingã€‚
    # é€™è£¡å‡è¨­ COSMIC_ID ä¸å…¥æ¨¡ã€‚

    X_cell_raw = df_clean[potential_cell_cols]
    
    # è‡ªå‹•è­˜åˆ¥ object é¡å‹çš„æ¬„ä½é€²è¡Œ One-Hot
    categorical_cell_cols = X_cell_raw.select_dtypes(include=['object']).columns.tolist()
    
    # ä½¿ç”¨ get_dummies é€²è¡Œ One-Hot
    X_cell_processed = pd.get_dummies(X_cell_raw, columns=categorical_cell_cols, drop_first=False)
    X_cell_processed = X_cell_processed.astype(float)
    
    print(f"   -> ç´°èƒç‰¹å¾µè™•ç†å®Œæˆã€‚ç¶­åº¦: {X_cell_processed.shape}")

    # ---------------------------------------------------------
    # 2. è™•ç† Target ç‰¹å¾µ (Multi-Hot Encoding)
    # ---------------------------------------------------------
    print("ğŸ”„ è™•ç† Target ç‰¹å¾µ (Multi-Hot Encoding)...")
    targets = df_clean[target_col].fillna('Unknown').astype(str)
    targets_split = targets.apply(lambda x: [t.strip() for t in x.split(',')])
    mlb_target = MultiLabelBinarizer()
    X_target_encoded = mlb_target.fit_transform(targets_split)
    print(f"   -> Target ç·¨ç¢¼å®Œæˆã€‚ç¶­åº¦: {X_target_encoded.shape}")
    
    # ---------------------------------------------------------
    # 3. è™•ç† Pathway ç‰¹å¾µ (One-Hot Encoding)
    # ---------------------------------------------------------
    print("ğŸ”„ è™•ç† Pathway ç‰¹å¾µ (One-Hot Encoding)...")
    pathways = df_clean[pathway_col].fillna('Unknown').astype(str)
    X_pathway_encoded = pd.get_dummies(pathways).astype(float).values
    print(f"   -> Pathway ç·¨ç¢¼å®Œæˆã€‚ç¶­åº¦: {X_pathway_encoded.shape}")

    # ---------------------------------------------------------
    # 4. è™•ç†è—¥ç‰©ç‰¹å¾µ (Numeric & ID Embedding)
    # ---------------------------------------------------------
    X_drug_numeric = pd.DataFrame() # æš«ç„¡å…¶ä»–æ•¸å€¼ç‰¹å¾µ
    # å¦‚æœæœªä¾†æœ‰ç‰©ç†åŒ–å­¸æ€§è³ªï¼Œåœ¨é€™è£¡åŠ å…¥
    # ç›®å‰ GDSC è³‡æ–™é›†ä¸»è¦åªæœ‰ ID å’Œ Target/Pathway
    
    # å¡«è£œç©ºçš„ numeric (é¿å… shape (N, 0) é€ æˆå•é¡Œï¼Œä½†æˆ‘å€‘ Model å·²ç¶“æœ‰è™•ç† dummy input)
    # ç‚ºäº†æ–¹ä¾¿ splitï¼Œé‚„æ˜¯ç”Ÿæˆä¸€å€‹ (N, 0) çš„ DF? 
    # è®“å®ƒä¿æŒ (N, 0)ï¼ŒModel æœƒè™•ç†ã€‚
    X_drug_numeric = pd.DataFrame(index=df_clean.index) # Empty DF with correct index
    
    # è™•ç† DRUG_ID Embedding
    X_drug_id = None
    drug_vocab_size = 0
    drug_le = None
    
    if include_ids and 'DRUG_ID' in df_clean.columns:
        print("ğŸ”„ è™•ç† Drug ID (Label Encoding for Embedding)...")
        drug_le = LabelEncoder()
        # è½‰æˆå­—ä¸²å†ç·¨ç¢¼æ¯”è¼ƒä¿éšªï¼Œæˆ–è€…ç¢ºä¿æ˜¯ int
        drug_ids = df_clean['DRUG_ID'].astype(str)
        X_drug_id = drug_le.fit_transform(drug_ids).reshape(-1, 1) # (N, 1)
        drug_vocab_size = len(drug_le.classes_)
        print(f"   -> Drug ID ç·¨ç¢¼å®Œæˆã€‚Vocab Size: {drug_vocab_size}")
    else:
        # No_IDs æ¨¡å¼ï¼šçµ¦ä¸€å€‹å…¨ 0 çš„ dummy IDï¼Œä¸¦ä¸” vocab_size=0 è¡¨ç¤ºä¸ä½¿ç”¨ Embedding
        X_drug_id = np.zeros((len(df_clean), 1), dtype=int)
        drug_vocab_size = 0

    # ---------------------------------------------------------
    # 5. æ•´åˆèˆ‡åˆ†å‰²
    # ---------------------------------------------------------
    y = df_clean['LN_IC50']
    
    feature_names = {
        'cell': X_cell_processed.columns.tolist(),
        'drug_numeric': [],
        'target': list(mlb_target.classes_),
        'pathway': list(pd.get_dummies(pathways).columns),
        'drug_vocab_size': drug_vocab_size
    }
    
    # å›å‚³ dimensions
    # dims = (target_dim, pathway_dim, drug_vocab_size)
    dims = (X_target_encoded.shape[1], X_pathway_encoded.shape[1], drug_vocab_size)
    
    # Arrays to split
    # [Cell, DrugNum, DrugID, Target, Pathway, y]
    arrays = [X_cell_processed, X_drug_numeric, X_drug_id, X_target_encoded, X_pathway_encoded, y]
    
    # Split Strategy
    stratify_col = None
    
    # Method 2: Blind Cell Split (Prevent Data Leakage)
    if 'COSMIC_ID' in df_clean.columns:
        print("   -> æ¨¡å¼: Blind Cell Split (ä¾æ“š COSMIC_ID åˆ‡åˆ†)")
        from sklearn.model_selection import GroupShuffleSplit
        
        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
        groups = df_clean['COSMIC_ID']
        
        train_idx, test_idx = next(gss.split(X_cell_processed, y, groups=groups))
        
        def split_array(arr, tr_idx, te_idx):
            if hasattr(arr, 'iloc'): return arr.iloc[tr_idx], arr.iloc[te_idx]
            return arr[tr_idx], arr[te_idx]
            
        X_cell_tr, X_cell_te = split_array(X_cell_processed, train_idx, test_idx)
        X_drug_num_tr, X_drug_num_te = split_array(X_drug_numeric, train_idx, test_idx)
        X_drug_id_tr, X_drug_id_te = split_array(X_drug_id, train_idx, test_idx)
        X_target_tr, X_target_te = split_array(X_target_encoded, train_idx, test_idx)
        X_pathway_tr, X_pathway_te = split_array(X_pathway_encoded, train_idx, test_idx)
        y_tr, y_te = split_array(y, train_idx, test_idx)
        
        # Verify
        train_cells = set(df_clean.iloc[train_idx]['COSMIC_ID'])
        test_cells = set(df_clean.iloc[test_idx]['COSMIC_ID'])
        overlap = train_cells.intersection(test_cells)
        print(f"      [Check] Train Cells: {len(train_cells)}, Test Cells: {len(test_cells)}, Overlap: {len(overlap)}")
        
    else:
        print("   âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° COSMIC_IDï¼Œé€€å› Stratified Split")
        if 'GDSC Tissue descriptor 1' in df_clean.columns:
            stratify_col = df_clean['GDSC Tissue descriptor 1'].fillna('Unknown')
            
        split_res = train_test_split(*arrays, test_size=0.2, random_state=42, stratify=stratify_col)
        # Unpack 6 pairs
        X_cell_tr, X_cell_te = split_res[0], split_res[1]
        X_drug_num_tr, X_drug_num_te = split_res[2], split_res[3]
        X_drug_id_tr, X_drug_id_te = split_res[4], split_res[5]
        X_target_tr, X_target_te = split_res[6], split_res[7]
        X_pathway_tr, X_pathway_te = split_res[8], split_res[9]
        y_tr, y_te = split_res[10], split_res[11]

    print(f"âœ… è³‡æ–™åˆ†å‰²å®Œæˆ (DL):")
    print(f"   X_cell_train: {X_cell_tr.shape}")
    print(f"   Drug ID Vocab: {drug_vocab_size}")
    
    encoders = {'mlb_target': mlb_target, 'drug_le': drug_le} 
    
    # Return 5 input arrays per set now
    return (X_cell_tr, X_drug_num_tr, X_drug_id_tr, X_target_tr, X_pathway_tr), \
           (X_cell_te, X_drug_num_te, X_drug_id_te, X_target_te, X_pathway_te), \
           y_tr, y_te, \
           feature_names, encoders, dims
